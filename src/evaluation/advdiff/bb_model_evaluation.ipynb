{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Advection diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "from src.nnets.utils import load_model\n",
    "from src.data_loader.data_loader import get_data_loader\n",
    "from src.data_loader.config_data_loader import SimulatorDataset\n",
    "from src.forward_models.init_physics_model import init_physics_solver_model\n",
    "from src.metrics.mmd import MMDLoss, RBF, estimate_mmd_bandwidth\n",
    "from src.evaluation.evaluator import one_to_many_evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"advdiff\"\n",
    "test_exp_name = \"ac9b06feb779781d54bdb5d8191edd00\"\n",
    "dataset_file_path = f\"../../../datasets/forward_models/advdiff/one_to_many/testing/data_{test_exp_name}\"\n",
    "path_model_file = f\"../../../outputs/best_models/advdiff/ac9b/euler/blackbox/a8f4feaea3835b0f74c953fd537af5da/VDN8_score_0.54_epoch_9800/model_587bb13f417afaf415ead7ad0951e98d_exp_3ca6aaf4c2ce8bfff7b41801b2c141b2_a8f4feaea3835b0f74c953fd537af5da_salt_VDN8_best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(13)\n",
    "np.random.seed(13)\n",
    "\n",
    "# Load the model\n",
    "params_dim = 1\n",
    "T_model, parent_dir, config, _ = load_model(\n",
    "    path_model_file=path_model_file,\n",
    "    params_dim=params_dim,\n",
    ")\n",
    "\n",
    "test_dataset = SimulatorDataset(\n",
    "    name_dataset=task_name,\n",
    "    data_file_path=dataset_file_path,\n",
    "    testing_set=True,\n",
    "    device=device,\n",
    ")\n",
    "test_loader = get_data_loader(\n",
    "    test_dataset, batch_size=512\n",
    ")  # batch size can be adjusted\n",
    "bandwidth = estimate_mmd_bandwidth(test_loader, median_heuristic=True)\n",
    "\n",
    "rbf = RBF(bandwidth=bandwidth, n_kernels=6, device=device)\n",
    "metrics = [MMDLoss(kernel=rbf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = test_loader.sample()\n",
    "test_params = test_samples[\"params\"]\n",
    "test_sims = test_samples[\"x\"]\n",
    "x_dim = test_sims.shape[2:]\n",
    "test_init_conds = test_samples[\"init_conds\"]\n",
    "print(test_params.shape)\n",
    "print(test_init_conds.shape)\n",
    "print(test_sims.shape)\n",
    "# Retrieve the parameters and initial conditions for the incomplete model\n",
    "noisy_samples = test_params.shape[\n",
    "    1\n",
    "]  # number of stochastic samples\n",
    "print(f\"Test number of noisy samples per parameter: {noisy_samples}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_params = test_params[\n",
    "    :, ::noisy_samples, :, :params_dim\n",
    "].squeeze(1)\n",
    "\n",
    "X_init_conds = test_init_conds[:, ::noisy_samples].squeeze(\n",
    "    1\n",
    ")\n",
    "phys_solver = init_physics_solver_model(config=config, device=device)\n",
    "res_sims = phys_solver(init_conds=X_init_conds, params=X_params)\n",
    "X_sims = res_sims[\"x\"]\n",
    "# Print shapes\n",
    "print(X_params.shape)\n",
    "print(X_init_conds.shape)\n",
    "print(X_sims.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OT OdeNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_noisy_samples = noisy_samples\n",
    "pred = T_model.predict(X_sims, context=X_params, z_samples=T_noisy_samples)\n",
    "pred = pred.reshape((-1, T_noisy_samples) + (x_dim))\n",
    "pred = pred.reshape((-1, T_noisy_samples) + (x_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_eval = one_to_many_evaluation(\n",
    "    X_params,\n",
    "    pred,\n",
    "    test_sims,\n",
    "    metrics=metrics,\n",
    "    type_evals=[\"marginal_score\"]\n",
    ")\n",
    "scores = res_eval[\"lik_score\"]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples = 10\n",
    "xi = list(range(X_sims.shape[-1]))\n",
    "x_labels = T_model.t_intg.detach().cpu().tolist()\n",
    "x_labels = [\"%.2f\"%item for item in x_labels]\n",
    "\n",
    "for j in range(0, plot_samples):\n",
    "    random_idx = np.random.randint(0, X_sims.shape[0])\n",
    "    print(random_idx)\n",
    "    kwargs = {'vmin':0.0, 'aspect':3.5, 'cmap':'magma', 'interpolation':'none'}\n",
    "    fig, axes = plt.subplots(2, noisy_samples+1, figsize=(30, 15))\n",
    "\n",
    "    param_0 = X_params.reshape(-1, 20)[random_idx].unique()\n",
    "    print(f\"Simple Model parameters \\n{param_0}\")\n",
    "    c_params = test_params[random_idx, :, 0].unique(dim=0)\n",
    "    print(f\"Complete Model parameters \\n{c_params}\")\n",
    "    #x axis format\n",
    "\n",
    "    axes[0, 0].imshow(X_sims[random_idx].detach().cpu().numpy(), **kwargs)\n",
    "    axes[0, 0].set_xticks(xi, x_labels, minor=False)\n",
    "    axes[0, 0].locator_params(axis='x', nbins=5)\n",
    "    axes[0, 0].set_title(f\"Simple model, coeff: {param_0.item():.4f}\")\n",
    "    # set x_axis range to be  T_model.t_intg.detach().cpu().tolist()\n",
    "    # axes[0, 0].set_xscale('function', functions=(lambda x: x, lambda x: x))\n",
    "\n",
    "    axes[1, 0].imshow(X_sims[random_idx].detach().cpu().numpy(), **kwargs)\n",
    "    axes[1, 0].set_xticks(xi, x_labels, minor=False)\n",
    "    axes[1, 0].locator_params(axis='x', nbins=5)\n",
    "    axes[1, 0].set_title(f\"Simple model, coeff: {param_0.item():.4f}\")\n",
    "\n",
    "    for i in range(noisy_samples):\n",
    "        # Target\n",
    "        axes[0, i+1].imshow(test_sims[random_idx, i].detach().cpu().numpy(), **kwargs)\n",
    "        axes[0, i+1].set_xticks(xi, x_labels, minor=False)\n",
    "        axes[0, i+1].locator_params(axis='x', nbins=5)\n",
    "        axes[0, i+1].set_title(f\"+dcoeff: {c_params[i][1]:.4f}\")\n",
    "        \n",
    "        # Prediction\n",
    "        axes[1, i+1].imshow(pred[random_idx, i].detach().cpu().numpy(), **kwargs)\n",
    "        axes[0, i+1].set_xticks(xi, x_labels, minor=False)\n",
    "        axes[0, i+1].locator_params(axis='x', nbins=5)\n",
    "        axes[1, i+1].set_title(f\"Pred sample {i+1}\")\n",
    "    \n",
    "    #axes[0, 0].xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model's integrator setting\n",
    "T_model.len_episode = (4) * T_model.len_episode \n",
    "print(f\"Extrapolatin of {T_model.len_episode} steps\")\n",
    "T_model.t_intg = torch.linspace(0.0, T_model.dt* T_model.len_episode, T_model.len_episode, device=T_model.device)\n",
    "print(f\"Max time: {T_model.t_intg.max()}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    extr_pred = T_model.predict(X_sims, context=X_params, z_samples=T_noisy_samples)\n",
    "    extr_pred = extr_pred.reshape((-1, T_noisy_samples) + (extr_pred.shape[1:]))\n",
    "    #pred = pred.reshape((-1, T_noisy_samples) + (x_dim))\n",
    "    print(extr_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_params.shape)\n",
    "x_grid_dim = test_params.shape[2]\n",
    "params = test_params.reshape(-1, x_grid_dim, 2)\n",
    "new_init_conds = X_init_conds.reshape(-1, 1, x_grid_dim).repeat(1, 5,1)\n",
    "new_init_conds = new_init_conds.reshape(-1, x_grid_dim)\n",
    "print(params.shape, new_init_conds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_model\n",
    "phys_solver.len_episode = T_model.len_episode\n",
    "phys_solver.dt = T_model.dt\n",
    "phys_solver.t = T_model.t_intg\n",
    "\n",
    "\n",
    "res_extr_Y = phys_solver(init_conds=new_init_conds, params=params)\n",
    "Y_extr = res_extr_Y[\"x\"].reshape(-1, noisy_samples, x_grid_dim, phys_solver.len_episode)\n",
    "params = params.reshape(-1, noisy_samples, x_grid_dim, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extr_pred.shape, Y_extr.shape)\n",
    "assert torch.isclose(extr_pred.reshape(-1, 20, extr_pred.shape[-1])[:, :, 0], Y_extr.reshape(-1, 20, Y_extr.shape[-1])[:, :, 0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples = 10\n",
    "#xi = list(range(extr_pred.shape[-1]))\n",
    "x_labels = T_model.t_intg.detach().cpu().tolist()\n",
    "x_labels = [\"%.2f\"%item for item in x_labels]\n",
    "for j in range(0, plot_samples):\n",
    "    random_idx = np.random.randint(0, extr_pred.shape[0])\n",
    "    print(random_idx)\n",
    "    \n",
    "    fig, axes = plt.subplots(noisy_samples, 2, figsize=(15, 15))\n",
    "\n",
    "    param_0 = X_params.reshape(-1, 20)[random_idx].unique()\n",
    "    print(f\"Simple Model parameters \\n{param_0}\")\n",
    "    c_params = test_params[random_idx, :, 0].unique(dim=0)\n",
    "    print(f\"Complete Model parameters \\n{c_params}\")\n",
    "    \n",
    "    y_params_1 = params[random_idx, :, 0].unique(dim=0)\n",
    "    print(y_params_1.shape)\n",
    "    #x axis format\n",
    "\n",
    "    for i in range(noisy_samples):\n",
    "        # Prediction\n",
    "        #vmax = np.maximum(extr_pred[random_idx, i].max().item(), Y_extr[random_idx, i].max().item())\n",
    "        kwargs = {'vmin':0.0, 'vmax': 1.5, 'aspect':3.5, 'cmap':'magma', 'interpolation':'none'}\n",
    "        axes[i, 0].imshow(extr_pred[random_idx, i].detach().cpu().numpy(), **kwargs)\n",
    "        #axes[i].set_xticks(xi, x_labels, minor=False)\n",
    "        #axes[i].locator_params(axis='x', nbins=10)\n",
    "        axes[i, 0].set_title(f\"Pred sample {i+1}, dcoeff: {param_0.item():.4f}\")\n",
    "        \n",
    "        # Prediction\n",
    "        axes[i, 1].imshow(Y_extr[random_idx, i].detach().cpu().numpy(), **kwargs)\n",
    "        #axes[i].set_xticks(xi, x_labels, minor=False)\n",
    "        #axes[i].locator_params(axis='x', nbins=10)\n",
    "        axes[i, 1].set_title(f\"GD sample {i+1}, dcoeff: {param_0.item():.4f}, c-coeff: {y_params_1[i][1].tolist():.4f}\")\n",
    "    \n",
    "    #axes[0, 0].xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot-miss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
